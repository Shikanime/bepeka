{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utils packages\n",
        "import math\n",
        "from datetime import datetime\n",
        "from pathlib import Path, PurePosixPath\n",
        "\n",
        "# Visualization packages\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "# Analysis packages\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Model packages\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.experimental import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read dataset file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"data\" # Directory to drop collected data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hentais_df = pd.read_json(\n",
        "    Path(DATA_PATH) / \"preprocessed\" / \"metadata.ndjson\",\n",
        "    orient=\"records\",\n",
        "    lines=True,\n",
        "    encoding=\"utf8\"\n",
        ")\n",
        "hentais_df = hentais_df.assign(\n",
        "    filename=hentais_df[\"filename\"].apply(\n",
        "        lambda filename: [\n",
        "            str(PurePosixPath(DATA_PATH) / \"preprocessed\" / Path(filename))\n",
        "            for filename in filename\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "hentais_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation\n",
        "\n",
        "The following preparation steps aim to create training and validation sets that can be used for machine learning.\n",
        "For example, if a hentai tag is rare, we will remove it from the target variable.\n",
        "The model will not learn how to predict that genre if the data covering it is insufficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_label_frequency(labels):\n",
        "    style.use(\"fivethirtyeight\")\n",
        "    plt.figure(figsize=(14, 16))\n",
        "    sns.barplot(\n",
        "        y=labels.index.values,\n",
        "        x=labels,\n",
        "        order=labels.index\n",
        "    )\n",
        "    plt.title(\"Labels\", fontsize=14)\n",
        "    plt.xlabel(\"Frequency\")\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get label frequencies in descending order\n",
        "label_freq = hentais_df[\"tag\"].explode().value_counts()\n",
        "label_freq = label_freq / len(hentais_df[\"tag\"])\n",
        "plot_label_frequency(label_freq.head(70))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove infrequent labels\n",
        "\n",
        "We will consider as a rare label every label that is covered by less than 5% in our dataset.\n",
        "We will assume that rare labels are very hard to predict due to lack of sufficient data.\n",
        "The model that we will train later will not focus on predicting these labels.\n",
        "So, we need to make some transformation in the label column (tag) where we ignore infrequent labels by hiding them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LABEL_THRESHHOLD = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rare_labels_df = label_freq[label_freq < LABEL_THRESHHOLD]\n",
        "rare_labels_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove the rare tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hentais_df = hentais_df.assign(\n",
        "    tag=hentais_df[\"tag\"].apply(\n",
        "        lambda x: [l for l in x if l not in rare_labels_df]\n",
        "    )\n",
        ")\n",
        "hentais_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "hentais_df[\"num_favorites\"].plot.hist(\n",
        "    bins=100,\n",
        "    range=(0, 6000),\n",
        "    title=\"Favorites\"\n",
        ")\n",
        "plt.subplot(1, 2, 2)\n",
        "hentais_df[\"num_pages\"].plot.hist(\n",
        "    bins=100,\n",
        "    range=(0, 300),\n",
        "    title=\"Pages\"\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Most frequent pages numbers: \", (hentais_df[\"num_pages\"]\n",
        "                                        .value_counts()\n",
        "                                        .idxmax()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assuming that each unit contains sufficient context, that hentai of more than 30 pages are generally relatively consistent genre antologies over the time window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_TIMESTEP = 20 # Number of pages to build a contextual classification of hentai tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hentais_df = hentais_df.assign(\n",
        "    filename=hentais_df.apply(\n",
        "        lambda x: [\n",
        "            x[\"filename\"][i:i + IMG_TIMESTEP]\n",
        "            for i in range(0, len(x[\"filename\"]), IMG_TIMESTEP)\n",
        "        ],\n",
        "        axis=1\n",
        "    )\n",
        ")\n",
        "hentais_df = hentais_df.explode(\"filename\")\n",
        "hentais_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image examples\n",
        "\n",
        "Let's display some examples of training images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "hentai_sample_df = (\n",
        "    hentais_df\n",
        "    .explode(\"filename\")\n",
        "    .sample(10)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "for i, row in enumerate(hentai_sample_df.iterrows()):\n",
        "    plt.subplot(2, 5, int(i) + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(Image.open(str(row[1][\"filename\"])))\n",
        "    plt.title(str(row[1][\"id\"]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation\n",
        "\n",
        "Convert variable size list to Ragged Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = tf.ragged.constant(hentais_df[\"filename\"].to_numpy())\n",
        "y = tf.ragged.constant(hentais_df[\"tag\"].to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The original targets are lists of strings that can be easily understood by humans.\n",
        "But, if we want to build and train a neural network we need to create binary labels (multi-hot encoding).\n",
        "This is critical for multi-label classification.\n",
        "\n",
        "In order to binarize our labels, we will be using keras's category encoding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a index of the feature values and encode the integer into one-hot vector\n",
        "label_indexer = keras.layers.StringLookup()\n",
        "label_indexer.adapt(y)\n",
        "\n",
        "# Encode interger indices to a one-hot vector\n",
        "label_category_encoder = keras.layers.CategoryEncoding(output_mode=\"binary\")\n",
        "label_category_encoder.adapt(label_indexer(y))\n",
        "\n",
        "# Build the category encoding model\n",
        "tokenizer = keras.Sequential([\n",
        "    label_indexer,\n",
        "    label_category_encoder\n",
        "])\n",
        "\n",
        "# Analyze the number of labels in the dataset for\n",
        "# the output layer of our subsequent model\n",
        "labels_df = pd.Series(tokenizer.get_vocabulary())\n",
        "labels_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform the targets of the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = tokenizer(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input pipeline\n",
        "\n",
        "If you are familiar with keras.preprocessing you may know the image data iterators (E.g. ImageDataGenerator, DirectoryIterator).\n",
        "These iterators are convenient for multi-class classfication where the image directory contains one subdirectory for each class.\n",
        "But, in the case of multi-label classification, having an image directory that respects this structure is not possible because one observation can belong to multiple classes at the same time.\n",
        "\n",
        "That is where the tf.data API has the upper hand.\n",
        "- It is faster.\n",
        "- It provides fine-grained control.\n",
        "- It is well integrated with the rest of TensorFlow.\n",
        "\n",
        "We first need to write some function to parse image files and generate a tensor representing the features and a tensor representing the labels.\n",
        "- In this function we can resize the image to adapt to the input expected by the model.\n",
        "- We can also normalize the pixel values to be between 0 and 1. This is a common practice that helps speed up the convergence of training.\n",
        "\n",
        "If we consider every pixel as a feature, we would like these features to have a similar range so that the gradients don't go out of control and that we only need one global learning rate multiplier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
        "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To train a model on our dataset we want the data to be:\n",
        "\n",
        "- Well shuffled\n",
        "- Batched\n",
        "- Batches to be available as soon as possible.\n",
        "\n",
        "These features can be easily added using the tf.data.Dataset abstraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32 # Big enough to measure an F1-score\n",
        "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
        "SUFFLE_SEED = 44 # Create reproductible train/test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AUTOTUNE will adapt the preprocessing and prefetching workload to model training and batch consumption.\n",
        "The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step.\n",
        "AUTOTUNE will prompt the tf.data runtime to tune the value dynamically at runtime and reduce GPU and CPU idle time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate datasets lenght\n",
        "dataset_len = len(hentais_df)\n",
        "val_len = math.floor(dataset_len * 0.2)\n",
        "train_len = dataset_len - val_len\n",
        "\n",
        "# Create dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "# Shuffle before train/test split\n",
        "dataset = dataset.shuffle(\n",
        "    buffer_size=SHUFFLE_BUFFER_SIZE,\n",
        "    seed=SUFFLE_SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze the number of labels in the dataset for the output layer of our subsequent model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlabels = tokenizer.vocabulary_size()\n",
        "print(\"Number of labels in the dataset : {}\".format(nlabels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform the targets of the training and test shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_image(example: tf.Tensor):\n",
        "    # Read an image from a file\n",
        "    image_string = tf.io.read_file(example)\n",
        "    # Decode it into a dense vector\n",
        "    image_decoded = tf.image.decode_image(\n",
        "        image_string,\n",
        "        channels=CHANNELS,\n",
        "        expand_animations=False\n",
        "    )\n",
        "    # Resize it to fixed shape\n",
        "    image_resized = tf.image.resize(\n",
        "        image_decoded,\n",
        "        [IMG_SIZE, IMG_SIZE]\n",
        "    )\n",
        "    return image_resized\n",
        "\n",
        "\n",
        "def read_image_set(example: tf.Tensor, label: tf.Tensor):\n",
        "    example = tf.map_fn(\n",
        "        fn=read_image,\n",
        "        elems=example,\n",
        "        fn_output_signature=tf.float32\n",
        "    )\n",
        "    return example, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read and preprocess images in parallel\n",
        "dataset = dataset.map(read_image_set, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Batch the data for multiple steps\n",
        "dataset = dataset.padded_batch(\n",
        "    BATCH_SIZE,\n",
        "    padded_shapes=(\n",
        "        [IMG_TIMESTEP, IMG_SIZE, IMG_SIZE, CHANNELS],\n",
        "        [nlabels]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train / val split\n",
        "\n",
        "Splitting the modeling data into training and validation is common in machine learning practice.\n",
        "We will be allocating 80% of the images for training and 20% for validation.\n",
        "Usually, we keep a final test set to communicate performance results but we will not really need it in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample test dataset\n",
        "val_ds = dataset.take(val_len)\n",
        "# Take the rest of the dataset for training\n",
        "train_ds = dataset.skip(val_len)\n",
        "# Fetch batches in the background while the model is training\n",
        "train_ds = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Establish a baseline\n",
        "\n",
        "Following development best practices, you should establish a baseline. The simplest baseline is predicting the most average classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Average class prediction baseline: {0:.0%}\".format(np.mean(y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfert Learning\n",
        "\n",
        "The feature extractor accepts images of shape (224, 224, 3) and returns a 1280-length vector for each image.\n",
        "\n",
        "We should freeze the variables in the feature extractor layer, so that the training only modifies the new classification layers.\n",
        "Usually, it is a good practice when working with datasets that are very small compared to the orginal dataset the feature extractor was trained on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "feature_extractor = keras.applications.InceptionV3(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS),\n",
        "    include_top=False,\n",
        "    pooling=\"max\"\n",
        ")\n",
        "feature_extractor.trainable = False\n",
        "feature_extractor.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS)),\n",
        "    keras.layers.RandomRotation(\n",
        "        factor=0.4,\n",
        "        fill_mode=\"wrap\"\n",
        "    ),\n",
        "    keras.layers.RandomTranslation(\n",
        "        height_factor=0.2,\n",
        "        width_factor=0.2,\n",
        "        fill_mode=\"wrap\"\n",
        "    ),\n",
        "    keras.layers.RandomContrast(factor=0.2),\n",
        "    keras.layers.Rescaling(1. / 255)\n",
        "])\n",
        "data_augmentation.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(IMG_TIMESTEP, IMG_SIZE, IMG_SIZE, CHANNELS)),\n",
        "    keras.layers.TimeDistributed(data_augmentation),\n",
        "    keras.layers.TimeDistributed(feature_extractor),\n",
        "    keras.layers.GRU(64),\n",
        "    keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(512, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(nlabels, activation=\"sigmoid\")\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_soft_f1(y: tf.Tensor, y_hat: tf.Tensor):\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    y_hat = tf.cast(y_hat, tf.float32)\n",
        "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
        "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "    soft_f1 = 2*tp / (2 * tp + fn + fp + 1e-16)\n",
        "    # Reduce 1 - soft-f1 in order to increase soft-f1\n",
        "    cost = 1 - soft_f1\n",
        "    # Average on all labels\n",
        "    macro_cost = tf.reduce_mean(cost)\n",
        "    return macro_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_f1(y: tf.Tensor, y_hat: tf.Tensor, thresh=0.5):\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2 * tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR = 1e-5 # Keep it small when transfer learning\n",
        "EPOCHS = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile the model to configure the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "  loss=macro_soft_f1,\n",
        "  metrics=[macro_f1]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we pass the training dataset of (features, labels) to fit the model and indicate a seperate dataset for validation.\n",
        "The performance on the validation dataset will be measured after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = Path(\"job\")\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "savedmodel_dir = output_dir / \"export\" / \"savedmodel\"\n",
        "model_export_path = savedmodel_dir / timestamp\n",
        "checkpoint_path = output_dir / \"checkpoints\"\n",
        "tensorboard_path = output_dir / \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(patience=3),\n",
        "        keras.callbacks.TensorBoard(\n",
        "            str(tensorboard_path),\n",
        "            histogram_freq=1\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            checkpoint_path,\n",
        "            save_weights_only=True,\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"macro_f1\"])\n",
        "plt.plot(history.history[\"val_macro_f1\"])\n",
        "plt.title(\"Macro F1\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"validation\"])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"validation\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show predictions\n",
        "\n",
        "We can try and see what the predictions will look like when using our model on pages of some known hentais.\n",
        "The following function simplifies the process of preparing images data, generating the prediction from the model and visualizing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\n",
        "    model_export_path,\n",
        "    custom_objects={\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"macro_soft_f1\": macro_soft_f1\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_image(path: str):\n",
        "    img = keras.utils.load_img(\n",
        "        path,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE, CHANNELS)\n",
        "    )\n",
        "    img = keras.utils.img_to_array(img)\n",
        "    img = img / 255\n",
        "    return img\n",
        "\n",
        "\n",
        "def plot_prediction(hentai: pd.Series):\n",
        "    # Get hentai info\n",
        "    img_paths = np.arange(1, 11)\n",
        "    img_paths = np.array([\n",
        "        str(Path(DATA_PATH) / \"preprocessed\" / str(hentai[\"id\"]) / \"{}.jpg\".format(x))\n",
        "        for x in img_paths\n",
        "    ])\n",
        "\n",
        "    # Read and prepare image\n",
        "    imgs = [\n",
        "        decode_image(img)\n",
        "        for img in img_paths[:IMG_TIMESTEP]\n",
        "    ]\n",
        "    imgs = np.expand_dims(imgs, axis=0)\n",
        "\n",
        "    # Generate prediction\n",
        "    prediction = model.predict(imgs)\n",
        "    prediction = pd.Series(prediction[0])\n",
        "    prediction = pd.concat([\n",
        "        labels_df.rename(\"label\"),\n",
        "        prediction.rename(\"prediction\")\n",
        "    ], axis=1)\n",
        "    prediction = prediction[prediction[\"prediction\"] > 0.5]\n",
        "    prediction = prediction[\"label\"]\n",
        "\n",
        "    # Display image with prediction\n",
        "    style.use(\"default\")\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.imshow(Image.open(img_paths[0]))\n",
        "    plt.title(\n",
        "        \"{}\\n\\nTag\\n{}\\n\\nPrediction\\n{}\\n\".format(\n",
        "            hentai[\"title\"],\n",
        "            hentai[\"tag\"],\n",
        "            list(prediction)\n",
        "        ),\n",
        "         fontsize=9\n",
        "    )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampled_hentais_df = hentais_df[\n",
        "    hentais_df[\"title\"].isin([\n",
        "        \"My Little Brother\",\n",
        "        \"Maotoko Rental Service\",\n",
        "        \"Maeoki wa Iranu Warawa to Asobe\",\n",
        "        \"Jigoku e no Katamichi 1 Credit\",\n",
        "        \"Makuu GB Tsuushin 3\"\n",
        "    ])\n",
        "]\n",
        "\n",
        "for _, sampled_hentai in sampled_hentais_df.iterrows():\n",
        "    plot_prediction(sampled_hentai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e2b07b63c14587a0e9eb03f2247eece484dfc8e712cf73a22aa52b4a1f37f8eb"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "metadata": {
      "interpreter": {
        "hash": "192fa43bbebb6a2bf664879821bb9b226440b6277539cdbfb00fb0188b28dc5b"
      }
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
