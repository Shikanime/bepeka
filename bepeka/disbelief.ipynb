{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disbelief\n",
    "\n",
    "The princess is in another castle. You need to find a way to get to her. But be\n",
    "careful, there are dragons in the way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "We will use a language model to generate a story, hallucinating a story and a\n",
    "personality for the princess. To do this, we will use the Google T5 model.\n",
    "Which is a transformer based model that can be used for text-to-text tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = widgets.Text(\n",
    "    value=(\n",
    "        \"summarize: Princess is a title used by a female member of a monarch's \"\n",
    "        \"family or by a female ruler. The male equivalent is a prince (from \"\n",
    "        \"Latin princeps, meaning principal citizen). Most often, the term has \"\n",
    "        \"been used for the consort of a prince, or for the daughter of a \"\n",
    "        \"monarch. A crown princess can be the heir apparent to the throne or \"\n",
    "        \"the heir apparent's spouse.\"\n",
    "    ),\n",
    "    placeholder=\"Type something\",\n",
    "    description=\"Input:\",\n",
    "    disabled=False,\n",
    ")\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer(input_text.value, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_tokens.input_ids, max_new_tokens=200)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on a large corpus of text, and can be used to generate\n",
    "text but also to answer questions. But for our task, this seems to be a little\n",
    "limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bepeka-UN3cu82L-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3c3a2622c4cff8880454b093cc51bb5e3889f7d1cdefa981fb5cdb4976c0df9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
