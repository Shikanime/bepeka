{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd051436f76c627f8be8713035cf2c451cb68cf413a7892f6e5abd4ad31fbc489ff",
   "display_name": "Python 3.8.9 64-bit ('3.8.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "df63770a6e32c921f58c3e8350f4a1433cfe774c3637c307e8a6bdb12178c3a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "from textwrap import wrap\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hentai import Utils, Hentai, Option\n",
    "from pathlib import Path"
   ]
  },
  {
   "source": [
    "## Data Collection\n",
    "\n",
    "We will be using the doujin dataset obtained from nhentai."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 0 # Number of sample to refetch from hentai."
   ]
  },
  {
   "source": [
    "## Download dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais = [Utils.get_random_hentai() for _ in range(0, N_SAMPLE)]\n",
    "hentais = pd.DataFrame([hentai.dictionary(Option.all()) for hentai in hentais])\n",
    "if not os.path.isfile('data/metadata.csv'):\n",
    "   hentais.to_csv('data/metadata.csv', index=False, header='column_names')\n",
    "else:\n",
    "   hentais.to_csv('data/metadata.csv', index=False, mode='a', header=False)\n",
    "print(\"Number of resampled hentais: \", len(hentais))\n"
   ]
  },
  {
   "source": [
    "## Read dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = {\n",
    "    column_name: ast.literal_eval\n",
    "    for column_name in [\"tag\", \"group\", \"parody\", \"character\", \"artist\", \"category\", \"image_urls\"]\n",
    "}\n",
    "hentais = pd.read_csv(\"data/metadata.csv\", converters=converters)\n",
    "hentais"
   ]
  },
  {
   "source": [
    "## Download images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, hentai in hentais.iterrows():\n",
    "    path = Path(\"data\") / str(hentai.id)\n",
    "    if not os.path.isdir(path):\n",
    "        hentai = Hentai(hentai.id)\n",
    "        hentai.download(path, progressbar=True)"
   ]
  },
  {
   "source": [
    "## Data preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_freq = hentais['tag'].explode().value_counts().sort_values(ascending=False).head(50)\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12, 20))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Label frequency\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Data sparsity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nobjs = 2 # Maximum number of images to display\n",
    "ncols = 2 # Number of columns in display\n",
    "nrows = nobjs // ncols # Number of rows in display\n",
    "plt.figure(figsize=(14, 4 * nrows))\n",
    "hentais[\"num_favorites\"].plot(ax=plt.subplot(nrows, ncols, 1), title=\"Favorites\")\n",
    "hentais[\"num_pages\"].plot(ax=plt.subplot(nrows, ncols, 2), title=\"Pages\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Train / val split\n",
    "\n",
    "We need to complete the full path to locate training and test images from the current working directory.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_re = re.compile(r\"https://i.nhentai.net/galleries/\\d+\")\n",
    "filenames = hentais.apply(lambda x: [image_url_re.sub(os.path.join(\"data\", str(x[\"id\"])), img) for img in x[\"image_urls\"]], axis=1).rename(\"filenames\")\n",
    "labels = hentais[\"tag\"].rename(\"labels\")\n",
    "pd.concat([filenames, labels], axis=1)"
   ]
  },
  {
   "source": [
    "Splitting the modeling data into training and validation is common in machine learning practice.\n",
    "We will be allocating 80% of the images for training and 20% for validation.\n",
    "Usually, we keep a final test set to communicate performance results but we will not really need it in this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(filenames, labels, test_size=0.2, random_state=44)\n",
    "print(\"Number of posters for training: \", len(X_train))\n",
    "print(\"Number of posters for validation: \", len(X_val))"
   ]
  },
  {
   "source": [
    "## Image examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nobjs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobjs // ncols # Number of rows in display\n",
    "samples = X_train.explode().sample(nrows * ncols)\n",
    "plt.figure(figsize=(14, 4 * nrows))\n",
    "for i, img in enumerate(samples):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    ax.imshow(plt.imread(img, format=\"jpeg\"))"
   ]
  },
  {
   "source": [
    "## Label encoding\n",
    "\n",
    "The original targets are lists of strings that can be easily understood by humans.\n",
    "But, if we want to build and train a neural network we need to create binary labels (multi-hot encoding).\n",
    "This is critical for multi-label classification.\n",
    "\n",
    "In order to binarize our labels, we will be using scikit-learn's MultiLabelBinarizer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(hentais[\"tag\"])\n",
    "\n",
    "# Loop over all labels and show them\n",
    "nlabels = len(mlb.classes_)\n",
    "\n",
    "pd.DataFrame({\"labels\": mlb.classes_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the targets of the training and test sets\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)"
   ]
  },
  {
   "source": [
    "Let's check if everything worked correctly (We should obtain binary targets instead of list of strings)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example of movie posters and their binary targets\n",
    "pd.DataFrame(zip(X_train, y_train_bin), columns=[\"filename\", \"labels\"])"
   ]
  },
  {
   "source": [
    "## Tensorflow DataSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FRAMES = 15 # Number of image sequence to feed into the ResNet\n",
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    filenames = filenames.apply(lambda x: x[1])\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin)"
   ]
  },
  {
   "source": [
    "## Transfert learning feature extractor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "cnn_model = keras.applications.InceptionV3(include_top=False, weights=\"imagenet\", pooling=\"max\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS)),\n",
    "    cnn_model,\n",
    "    # layers.TimeDistributed(cnn_model),\n",
    "    # layers.GRU(64),\n",
    "    layers.Dense(1024, activation=\"relu\"),\n",
    "    layers.Dropout(.5),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dropout(.5),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(nlabels, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Train the model\n",
    "Specify the learning rate and the number of training epochs (number of loops over the whole dataset)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}