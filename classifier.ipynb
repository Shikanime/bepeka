{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd051436f76c627f8be8713035cf2c451cb68cf413a7892f6e5abd4ad31fbc489ff",
   "display_name": "Python 3.8.9 64-bit ('3.8.9')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils packages\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from pathlib import Path, PurePath\n",
    "from typing import List\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Analysis packages\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "source": [
    "## Read dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "DATA_PATH = \"data\" # Directory to drop collected data."
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = pd.read_csv(\n",
    "    Path(DATA_PATH) / \"preprocessed\" / \"metadata.csv\",\n",
    "    index_col=None,\n",
    "    converters={\n",
    "        column_name: ast.literal_eval\n",
    "        for column_name in [\"tag\", \"group\", \"parody\", \"character\", \"artist\", \"category\", \"image_urls\"]\n",
    "    }\n",
    ")\n",
    "hentais_df"
   ]
  },
  {
   "source": [
    "## Data preparation\n",
    "\n",
    "The following preparation steps aim to create training and validation sets that can be used for machine learning.\n",
    "For example, if a hentai tag is rare, we will remove it from the target variable.\n",
    "The model will not learn how to predict that genre if the data covering it is insufficient."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label frequencies in descending order\n",
    "label_freq = hentais_df[\"tag\"].explode().value_counts()\n",
    "label_freq = label_freq / len(hentais_df[\"tag\"])\n",
    "label_freq = label_freq.head(70)\n",
    "\n",
    "# Bar plot\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12, 16))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Labels\", fontsize=14)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Remove infrequent labels\n",
    "\n",
    "We will consider as a rare label every label that is covered by less than 5% in our dataset.\n",
    "We will assume that rare labels are very hard to predict due to lack of sufficient data.\n",
    "The model that we will train later will not focus on predicting these labels.\n",
    "So, we need to make some transformation in the label column (tag) where we ignore infrequent labels by hiding them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_label_df = label_freq[label_freq < 0.05]\n",
    "rare_label_df"
   ]
  },
  {
   "source": [
    "Transform Genre into a list of labels and remove the rare ones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df[\"tag\"] = hentais_df[\"tag\"].apply(lambda x: [l for l in x if l not in rare_label_df])\n",
    "hentais_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "hentais_df[\"num_favorites\"].plot.hist(ax=plt.subplot(1, 2, 1), bins=100, title=\"Favorites\")\n",
    "hentais_df[\"num_pages\"].plot.hist(ax=plt.subplot(1, 2, 2), bins=100, title=\"Pages\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We need to complete the full path to locate training and test images from the current working directory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hentai_filename(hentai: pd.Series):\n",
    "    return str(PurePath(DATA_PATH) / \"preprocessed\" / str(hentai[\"id\"]) / Path(hentai[\"image_url\"]).name)\n",
    "\n",
    "hentais_df = hentais_df.explode(\"image_urls\", ignore_index=True).rename(columns={\"image_urls\": \"image_url\"})\n",
    "hentais_df = hentais_df.assign(filename=hentais_df.apply(hentai_filename, axis=1))\n",
    "hentais_df"
   ]
  },
  {
   "source": [
    "## Remove non-JPG images\n",
    "\n",
    "For practical reasons, we will stick with JPG images for the moment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = hentais_df[hentais_df[\"filename\"].str.endswith(\".jpg\")]"
   ]
  },
  {
   "source": [
    "## Image examples\n",
    "\n",
    "Let's display some examples of training images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobjs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobjs // ncols # Number of rows in display\n",
    "\n",
    "plt.figure(figsize=(14, 4 * nrows))\n",
    "for i, filename in enumerate(hentais_df[\"filename\"].sample(nrows * ncols)):\n",
    "    ax = plt.subplot(nrows, ncols, i + 1)\n",
    "    ax.imshow(Image.open(filename).convert(\"RGB\"))"
   ]
  },
  {
   "source": [
    "## Train / val split\n",
    "\n",
    "Splitting the modeling data into training and validation is common in machine learning practice.\n",
    "We will be allocating 80% of the images for training and 20% for validation.\n",
    "Usually, we keep a final test set to communicate performance results but we will not really need it in this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = hentais_df[\"filename\"].to_numpy(), hentais_df[\"tag\"].to_numpy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=44)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=44)\n",
    "\n",
    "print(\"Number of hentais for training: \", len(X_train))\n",
    "print(\"Number of hentais for validation: \", len(X_val))\n",
    "print(\"Number of hentais for test: \", len(X_test))"
   ]
  },
  {
   "source": [
    "## Label encoding\n",
    "\n",
    "The original targets are lists of strings that can be easily understood by humans.\n",
    "But, if we want to build and train a neural network we need to create binary labels (multi-hot encoding).\n",
    "This is critical for multi-label classification.\n",
    "\n",
    "In order to binarize our labels, we will be using scikit-learn's MultiLabelBinarizer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Analyze the number of labels in the dataset for\n",
    "# the output layer of our subsequent model.\n",
    "labels_df = pd.Series(mlb.classes_)\n",
    "labels_df"
   ]
  },
  {
   "source": [
    "Analyze the number of labels in the dataset for the output layer of our subsequent model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabels = len(labels_df)"
   ]
  },
  {
   "source": [
    "transform the targets of the training and test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "y_test_bin = mlb.transform(y_test)"
   ]
  },
  {
   "source": [
    "## Input pipeline\n",
    "\n",
    "If you are familiar with keras.preprocessing you may know the image data iterators (E.g. ImageDataGenerator, DirectoryIterator).\n",
    "These iterators are convenient for multi-class classfication where the image directory contains one subdirectory for each class.\n",
    "But, in the case of multi-label classification, having an image directory that respects this structure is not possible because one observation can belong to multiple classes at the same time.\n",
    "\n",
    "That is where the tf.data API has the upper hand.\n",
    "- It is faster.\n",
    "- It provides fine-grained control.\n",
    "- It is well integrated with the rest of TensorFlow.\n",
    "\n",
    "We first need to write some function to parse image files and generate a tensor representing the features and a tensor representing the labels.\n",
    "- In this function we can resize the image to adapt to the input expected by the model.\n",
    "- We can also normalize the pixel values to be between 0 and 1. This is a common practice that helps speed up the convergence of training.\n",
    "\n",
    "If we consider every pixel as a feature, we would like these features to have a similar range so that the gradients don't go out of control and that we only need one global learning rate multiplier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename: tf.Tensor, label: int) -> (tf.Tensor, List[int]):\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_image(image_string, channels=CHANNELS, expand_animations=False)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "source": [
    "To train a model on our dataset we want the data to be:\n",
    "\n",
    "- Well shuffled\n",
    "- Batched\n",
    "- Batches to be available as soon as possible.\n",
    "\n",
    "These features can be easily added using the tf.data.Dataset abstraction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "source": [
    "AUTOTUNE will adapt the preprocessing and prefetching workload to model training and batch consumption.\n",
    "The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step.\n",
    "AUTOTUNE will prompt the tf.data runtime to tune the value dynamically at runtime and reduce GPU and CPU idle time.\n",
    "\n",
    "We can now create a function that generates training and validation datasets for TensorFlow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames: List[str], labels: List[int], is_training: bool=True) -> tf.data.Dataset:\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin)"
   ]
  },
  {
   "source": [
    "Each batch will be a pair of arrays (one that holds the features and another one that holds the labels).\n",
    "The features array will be of shape (BATCH_SIZE, IMG_SIZE, IMG_SIZE, CHANNELS).\n",
    "The labels array will be of shape (BATCH_SIZE, N_LABELS) where N_LABELS is the maximum number of labels.\n",
    "Let's verify the shapes of these arrays by analyzing the first batch:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ]
  },
  {
   "source": [
    "## Transfert Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    ")"
   ]
  },
  {
   "source": [
    "The feature extractor accepts images of shape (224, 224, 3) and returns a 1280-length vector for each image.\n",
    "\n",
    "We should freeze the variables in the feature extractor layer, so that the training only modifies the new classification layers.\n",
    "Usually, it is a good practice when working with datasets that are very small compared to the orginal dataset the feature extractor was trained on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "source": [
    "## Main Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation=\"relu\"),\n",
    "    layers.Dense(nlabels, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Model training and evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 30"
   ]
  },
  {
   "source": [
    "Compile the model to configure the training process."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=\"binary_crossentropy\",\n",
    "  metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "source": [
    "Now, we pass the training dataset of (features, labels) to fit the model and indicate a seperate dataset for validation.\n",
    "The performance on the validation dataset will be measured after each epoch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"job\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "savedmodel_dir = output_dir / \"export\" / \"savedmodel\"\n",
    "model_export_path = savedmodel_dir / timestamp\n",
    "checkpoint_path = output_dir / \"checkpoints\"\n",
    "tensorboard_path = output_dir / \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(),\n",
    "        keras.callbacks.EarlyStopping(patience=2),\n",
    "        keras.callbacks.TensorBoard(str(tensorboard_path)),\n",
    "        keras.callbacks.ModelCheckpoint(str(checkpoint_path)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.plot(history.history[\"accuracy\"])\n",
    "ax.plot(history.history[\"val_accuracy\"])\n",
    "ax.title(\"model accuracy\")\n",
    "ax.ylabel(\"accuracy\")\n",
    "ax.xlabel(\"epoch\")\n",
    "ax.legend([\"train\", \"validation\"])\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.plot(history.history[\"loss\"])\n",
    "ax.plot(history.history[\"val_loss\"])\n",
    "ax.title(\"model loss\")\n",
    "ax.ylabel(\"loss\")\n",
    "ax.xlabel(\"epoch\")\n",
    "ax.legend([\"train\", \"validation\"])\n",
    "plt.show()"
   ]
  }
 ]
}