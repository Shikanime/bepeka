{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd097ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils packages\n",
    "import ast\n",
    "import itertools\n",
    "from math import ceil\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Union\n",
    "\n",
    "# Data collector packages\n",
    "from hentai import Utils, Hentai, Option, Sort\n",
    "\n",
    "# Analysis packages\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Compute packages\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "## Data collection\n",
    "\n",
    "We will use the information and media collected on the nhentai.net website. Recording each entry in a 'metadata.csv' file that aggregates information about the hentai, including links to download pages."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 20 # Number of sample to refetch from hentai.\n",
    "DATA_PATH = \"data\" # Directory to drop collected data.\n",
    "SEARCH_QUERY = \"tag:uncensored\" # nhentai search query.\n",
    "HENTAI_IDS = [120621, 80561] # Manual Hentai IDs to download.\n",
    "COLLECT_MODE = \"manual\" # Sampling mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hentai_info(hentai: Hentai):\n",
    "    return hentai.dictionary(Option.all())\n",
    "\n",
    "\n",
    "def get_random_hentai():\n",
    "    hentai = Utils.get_random_hentai()\n",
    "    hentai = get_hentai_info(hentai)\n",
    "    return hentai\n",
    "\n",
    "\n",
    "def search_hentai(query: str, page: int):\n",
    "    return Utils.search_by_query(\n",
    "        query,\n",
    "        page,\n",
    "        sort=Sort.PopularMonth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the nhentai.net API to get N number of random hentai\n",
    "if COLLECT_MODE == \"search\":\n",
    "    collected_hentais_df = pd.DataFrame([\n",
    "        pd.Series(get_hentai_info(h))\n",
    "        for hs in [\n",
    "            search_hentai(SEARCH_QUERY, p)\n",
    "            for p in range(1, ceil(N_SAMPLE / 25) + 1)\n",
    "        ]\n",
    "        for h in hs\n",
    "    ])\n",
    "elif COLLECT_MODE == \"random\":\n",
    "    collected_hentais_df = pd.DataFrame([\n",
    "        pd.Series(get_random_hentai())\n",
    "        for _ in range(N_SAMPLE)\n",
    "    ])\n",
    "else:\n",
    "    collected_hentais_df = pd.DataFrame([\n",
    "        pd.Series(get_hentai_info(Hentai(h)))\n",
    "        for h in HENTAI_IDS\n",
    "    ])\n",
    "collected_hentais_df"
   ]
  },
  {
   "source": [
    "## Read dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metadata NDJSON file that will contain the raw information about the hentai\n",
    "metadata_path = Path(DATA_PATH) / \"raw\" / \"metadata.ndjson\""
   ]
  },
  {
   "source": [
    "hentais_df = pd.read_json(\n",
    "    metadata_path,\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")\n",
    "hentais_df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Save collected dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = pd.concat([collected_hentais_df, hentais_df], ignore_index=True)\n",
    "hentais_df = hentais_df.drop_duplicates(\"id\")\n",
    "hentais_df.to_json(\n",
    "    metadata_path,\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "source": [
    "## Download images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hentai(hentai: pd.Series):\n",
    "    # A hentai will be stored based on the gallery ID instead of the medai ID\n",
    "    hentai_path = Path(DATA_PATH) / \"raw\" / str(hentai.id)\n",
    "    # Since downloading a hentai is an expensive operation, we only\n",
    "    # download when the hentai ID directory does not exist\n",
    "    if not hentai_path.is_dir():\n",
    "        try:\n",
    "            hentai = Hentai(hentai.id)\n",
    "            hentai.download(folder=hentai_path, progressbar=True)\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_hentais_df = hentais_df.apply(download_hentai, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of downloaded hentais : {}\".format(downloaded_hentais_df.sum()))"
   ]
  },
  {
   "source": [
    "## Remove corrupted images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hentai_filenames(hentai: pd.Series):\n",
    "    return [\n",
    "        str(PurePath(str(hentai[\"id\"])) / Path(url).name)\n",
    "        for url in hentai[\"image_urls\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = hentais_df.assign(\n",
    "    filenames=hentais_df.apply(hentai_filenames, axis=1)\n",
    ")\n",
    "hentais_df"
   ]
  },
  {
   "source": [
    "We will filter every hentais that contain at least one corrupted images, since pages have order dependencies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename: str):\n",
    "    image_path = Path(filename)\n",
    "    image_preproc_dir = Path(DATA_PATH) / \"preprocessed\" / image_path.parent\n",
    "    image_preproc_path = image_preproc_dir / Path(image_path.stem + \".jpg\")\n",
    "    # Preprocess only those images that do not exist in\n",
    "    # the destination dataset for performance reason\n",
    "    if not image_preproc_path.is_file():\n",
    "        try:\n",
    "            image = Image.open(Path(DATA_PATH) / \"raw\" / image_path)\n",
    "            # Normalize images to be JPEG compatible\n",
    "            image = image.convert(\"RGB\")\n",
    "            image_preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "            image.save(image_preproc_path, \"JPEG\")\n",
    "        except Exception:\n",
    "            return None\n",
    "    return str(PurePath(image_preproc_path))\n",
    "\n",
    "\n",
    "def preprocess_images(hentai: pd.Series):\n",
    "    return [\n",
    "        preprocess_image(filename)\n",
    "        for filename in hentai[\"filenames\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "hentais_df = hentais_df.assign(\n",
    "    filenames=hentais_df.progress_apply(preprocess_images, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = hentais_df[hentais_df[\"filenames\"].apply(all)]\n",
    "hentais_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metadata CSV file that will contain the raw information about the hentai\n",
    "metadata_path = Path(DATA_PATH) / \"preprocessed\" / \"metadata.ndjson\"\n",
    "hentais_df = hentais_df[[\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"num_favorites\",\n",
    "    \"tag\",\n",
    "    \"group\",\n",
    "    \"parody\",\n",
    "    \"character\",\n",
    "    \"language\",\n",
    "    \"artist\",\n",
    "    \"category\",\n",
    "    \"num_pages\",\n",
    "    \"filenames\"\n",
    "]]\n",
    "hentais_df.to_json(\n",
    "    metadata_path,\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")\n",
    "print(\"Number of preprocessed images :\", len(hentais_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}