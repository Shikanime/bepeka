{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd051436f76c627f8be8713035cf2c451cb68cf413a7892f6e5abd4ad31fbc489ff",
   "display_name": "Python 3.8.9 64-bit ('3.8.9')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils packages\n",
    "import ast\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Union\n",
    "\n",
    "# Data collector packages\n",
    "from hentai import Utils, Hentai, Option\n",
    "\n",
    "# Analysis packages\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Compute packages\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "## Data collection\n",
    "\n",
    "We will use the information and media collected on the nhentai.net website. Recording each entry in a 'metadata.csv' file that aggregates information about the hentai, including links to download pages."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 0 # Number of sample to refetch from hentai.\n",
    "DATA_PATH = \"data\" # Directory to drop collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_hentai(_: int) -> pd.Series:\n",
    "    return pd.Series(Utils.get_random_hentai().dictionary(Option.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the nhentai.net API to get N number of random hentai\n",
    "hentais_df = pd.Series(range(N_SAMPLE))\n",
    "hentais_df = hentais_df.apply(random_hentai)\n",
    "\n",
    "# The metadata CSV file that will contain the raw information about the hentai\n",
    "metadata_path = Path(DATA_PATH) / \"raw\" / \"metadata.csv\"\n",
    "\n",
    "# Create a CSV file with a header only if the file does not exist\n",
    "if not metadata_path.is_file():\n",
    "    hentais_df.to_csv(metadata_path, index=False, header=\"column_names\")\n",
    "else:\n",
    "    hentais_df.to_csv(metadata_path, index=False, mode=\"a\", header=False)\n",
    "\n",
    "print(\"Number of collected hentais: \", len(hentais_df))"
   ]
  },
  {
   "source": [
    "## Read dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "hentais_df = pd.read_csv(\n",
    "    Path(DATA_PATH) / \"raw\" / \"metadata.csv\",\n",
    "    converters={\n",
    "        column_name: ast.literal_eval\n",
    "        for column_name in [\"tag\", \"group\", \"parody\", \"character\", \"artist\", \"category\", \"image_urls\"]\n",
    "    }\n",
    ")\n",
    "hentais_df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Download images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hentai(hentai: pd.Series) -> Hentai:\n",
    "    # A hentai will be stored based on the gallery ID instead of the medai ID\n",
    "    hentai_path = Path(DATA_PATH) / \"raw\" / str(hentai.id)\n",
    "\n",
    "    # Since downloading a hentai is an expensive operation, we only\n",
    "    # download when the hentai ID directory does not exist\n",
    "    if not hentai_path.is_dir():\n",
    "        hentai = Hentai(hentai.id)\n",
    "        hentai.download(hentai_path, progressbar=True)\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "downloaded_hentais_df = hentais_df.apply(download_hentai, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of downloaded hentais :\", len(hentais_df) - downloaded_hentais_df.sum())"
   ]
  },
  {
   "source": [
    "## Remove duplicates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = hentais_df.drop_duplicates(\"id\")\n",
    "hentais_df.to_csv(metadata_path, index=False, header=\"column_names\")"
   ]
  },
  {
   "source": [
    "## Remove corrupted images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hentai_filenames(hentai: pd.Series):\n",
    "    return [\n",
    "        str(PurePath(str(hentai[\"id\"])) / Path(url).name)\n",
    "        for url in hentai[\"image_urls\"]\n",
    "    ]\n",
    "\n",
    "hentais_df = hentais_df.assign(filenames=hentais_df.apply(hentai_filenames, axis=1))\n",
    "hentais_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(filename: str) -> bool:\n",
    "    image_path = Path(filename)\n",
    "    image_preproc_dir = Path(DATA_PATH) / \"preprocessed\" / image_path.parent\n",
    "    image_preproc_path = image_preproc_dir / Path(image_path.stem + \".jpg\")\n",
    "\n",
    "    # Preprocess only those images that do not exist in\n",
    "    # the destination dataset for performance reason\n",
    "    if not image_preproc_path.is_file():\n",
    "        try:\n",
    "            image = Image.open(Path(DATA_PATH) / \"raw\" / image_path)\n",
    "            # Normalize images to be JPEG compatible\n",
    "            image = image.convert(\"RGB\")\n",
    "            image_preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "            image.save(image_preproc_path, \"JPEG\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def preprocess_images(hentai: pd.Series) -> bool:\n",
    "    return [\n",
    "        preprocess_image(filename)\n",
    "        for filename in hentai[\"filenames\"]\n",
    "    ]\n",
    "\n",
    "tqdm.pandas()\n",
    "preprocessed_hentais_df = hentais_df.progress_apply(preprocess_images, axis=1)"
   ]
  },
  {
   "source": [
    "We will filter every hentais that contain at least one corrupted images, since pages have order dependencies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hentais_df = hentais_df[preprocessed_hentais_df.apply(all)]\n",
    "\n",
    "# The metadata CSV file that will contain the raw information about the hentai\n",
    "metadata_path = Path(DATA_PATH) / \"preprocessed\" / \"metadata.csv\"\n",
    "hentais_df.to_csv(metadata_path, index=False, header=\"column_names\")\n",
    "\n",
    "print(\"Number of preprocessed images :\", len(hentais_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}